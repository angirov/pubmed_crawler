{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iklCqJn-5E4g",
    "outputId": "f605ea67-bdf2-4077-e731-535e442b4085"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "DATA_PATH = \"data/2019-2023\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "tqoJx2Ka5RUI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2493 entries, 0 to 2492\n",
      "Data columns (total 6 columns):\n",
      " #   Column    Non-Null Count  Dtype         \n",
      "---  ------    --------------  -----         \n",
      " 0   id        2493 non-null   int64         \n",
      " 1   date      2493 non-null   datetime64[ns]\n",
      " 2   title     2493 non-null   object        \n",
      " 3   authors   2493 non-null   object        \n",
      " 4   keywords  2493 non-null   object        \n",
      " 5   abstract  2289 non-null   object        \n",
      "dtypes: datetime64[ns](1), int64(1), object(4)\n",
      "memory usage: 117.0+ KB\n"
     ]
    }
   ],
   "source": [
    "year = 2023\n",
    "pkl_name = os.path.join(DATA_PATH, str(year) + \"_all.pkl\")\n",
    "df_2023 = pd.read_pickle(pkl_name)\n",
    "df_2023.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "OSGaJxzE4mIj",
    "outputId": "ee17525a-f180-4e58-ff43-b07cf251eb25"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20851 entries, 0 to 20850\n",
      "Data columns (total 6 columns):\n",
      " #   Column    Non-Null Count  Dtype         \n",
      "---  ------    --------------  -----         \n",
      " 0   id        20851 non-null  int64         \n",
      " 1   date      20851 non-null  datetime64[ns]\n",
      " 2   title     20851 non-null  object        \n",
      " 3   authors   20851 non-null  object        \n",
      " 4   keywords  20851 non-null  object        \n",
      " 5   abstract  19201 non-null  object        \n",
      "dtypes: datetime64[ns](1), int64(1), object(4)\n",
      "memory usage: 977.5+ KB\n"
     ]
    }
   ],
   "source": [
    "year = 2022\n",
    "pkl_name = os.path.join(DATA_PATH, str(year) + \"_all.pkl\")\n",
    "df_2022 = pd.read_pickle(pkl_name)\n",
    "df_2022.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 22268 entries, 0 to 22267\n",
      "Data columns (total 6 columns):\n",
      " #   Column    Non-Null Count  Dtype         \n",
      "---  ------    --------------  -----         \n",
      " 0   id        22268 non-null  int64         \n",
      " 1   date      22268 non-null  datetime64[ns]\n",
      " 2   title     22268 non-null  object        \n",
      " 3   authors   22268 non-null  object        \n",
      " 4   keywords  22268 non-null  object        \n",
      " 5   abstract  20601 non-null  object        \n",
      "dtypes: datetime64[ns](1), int64(1), object(4)\n",
      "memory usage: 1.0+ MB\n"
     ]
    }
   ],
   "source": [
    "year = 2021\n",
    "pkl_name = os.path.join(DATA_PATH, str(year) + \"_all.pkl\")\n",
    "df_2021 = pd.read_pickle(pkl_name)\n",
    "df_2021.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 22994 entries, 0 to 22993\n",
      "Data columns (total 6 columns):\n",
      " #   Column    Non-Null Count  Dtype         \n",
      "---  ------    --------------  -----         \n",
      " 0   id        22994 non-null  int64         \n",
      " 1   date      22994 non-null  datetime64[ns]\n",
      " 2   title     22994 non-null  object        \n",
      " 3   authors   22994 non-null  object        \n",
      " 4   keywords  22994 non-null  object        \n",
      " 5   abstract  14515 non-null  object        \n",
      "dtypes: datetime64[ns](1), int64(1), object(4)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "year = 2020\n",
    "pkl_name = os.path.join(DATA_PATH, str(year) + \"_all.pkl\")\n",
    "df_2020 = pd.read_pickle(pkl_name)\n",
    "df_2020.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 21347 entries, 0 to 21346\n",
      "Data columns (total 6 columns):\n",
      " #   Column    Non-Null Count  Dtype         \n",
      "---  ------    --------------  -----         \n",
      " 0   id        21347 non-null  int64         \n",
      " 1   date      21347 non-null  datetime64[ns]\n",
      " 2   title     21347 non-null  object        \n",
      " 3   authors   21347 non-null  object        \n",
      " 4   keywords  21347 non-null  object        \n",
      " 5   abstract  11868 non-null  object        \n",
      "dtypes: datetime64[ns](1), int64(1), object(4)\n",
      "memory usage: 1000.8+ KB\n"
     ]
    }
   ],
   "source": [
    "year = 2019\n",
    "pkl_name = os.path.join(DATA_PATH, str(year) + \"_all.pkl\")\n",
    "df_2019 = pd.read_pickle(pkl_name)\n",
    "df_2019.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.concat([df_2023, df_2022, df_2021, df_2020, df_2019]).reset_index()\n",
    "# df = df.drop(columns=\"index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try small data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_2019.loc[:10000, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['authors'] = df['authors'].apply(lambda x: ast.literal_eval(x))\n",
    "relationships = []\n",
    "for idx in range(df.shape[0]):\n",
    "# Add a relationship to the list for each pair of unique characters within the window\n",
    "    if len(df.loc[idx, 'authors']) > 1:\n",
    "        for id, a in enumerate(df.loc[idx, 'authors'][:-1]):\n",
    "            b = df.loc[idx, 'authors'][id + 1]\n",
    "            relationships.append({\"source\": a, \"target\": b})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "relationship_df = pd.DataFrame(relationships)\n",
    "# Sort the cases with a->b and b->a\n",
    "relationship_df = pd.DataFrame(np.sort(relationship_df.values, axis = 1), columns = relationship_df.columns)\n",
    "\n",
    "# Add a new column with value 1 to the DataFrame\n",
    "relationship_df[\"value\"] = 1\n",
    "\n",
    "# Group the DataFrame by source and target, and sum the values\n",
    "relationship_df = relationship_df.groupby([\"source\", \"target\"], sort=False, as_index=False)[\"value\"].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# Create a graph from a pandas dataframe\n",
    "G = nx.from_pandas_edgelist(relationship_df, \n",
    "                            source = \"source\", \n",
    "                            target = \"target\", \n",
    "                            edge_attr = \"value\", \n",
    "                            create_using = nx.Graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = nx.spring_layout(G)\n",
    "\n",
    "# Extract the edge weights from the edge_attr dictionary\n",
    "edge_weights = [d[\"value\"] for _, _, d in G.edges(data=True)]\n",
    "\n",
    "# Scale the edge weights to the desired range and store them in a list\n",
    "scaled_edge_weights = [0.1 + 5 * (w - min(edge_weights)) / (max(edge_weights) - min(edge_weights)) \n",
    "                       for w in edge_weights]\n",
    "\n",
    "# Draw the nodes and edges with adjusted edge widths\n",
    "nx.draw_networkx_nodes(G, pos, node_size=1)\n",
    "nx.draw_networkx_edges(G, pos, alpha=0.5, width=scaled_edge_weights)\n",
    "\n",
    "plt.figure(figsize=(100,100))\n",
    "plt.axis('off')  # Disable axis\n",
    "plt.savefig('2019.pdf',dpi=300)\n",
    "plt.show()  # Show the plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "81SvArUm5gtf"
   },
   "outputs": [],
   "source": [
    "def is_str_lst(lst):\n",
    "  return isinstance(lst, list) and all(isinstance(elem, str) for elem in lst)\n",
    "  \n",
    "print(df['title'][df['title'].notnull()].apply(lambda x: isinstance(x, str)).mean())\n",
    "print(df['authors'][df['authors'].notnull()].apply(is_str_lst).mean())\n",
    "print(df['keywords'][df['keywords'].notnull()].apply(is_str_lst).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
