{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/angirov/pubmed_crawler/blob/main/process_xml.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "metadata": {
        "id": "uj5wt1vDocYV",
        "outputId": "433d43e2-2e1b-42db-c3b3-6c5728b0c7a4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "proj_dir = \"/gdrive/MyDrive/dsr/pubmed_data/\"\n",
        "os.chdir(proj_dir)\n",
        "os.getcwd()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "QpzgFsBKUyQ5",
        "outputId": "cf148766-6238-4b78-a641-8abb8dc7ff9c"
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/gdrive/MyDrive/dsr/pubmed_data'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {
        "id": "PvXoYTrlSlAe"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "\n",
        "from urllib.error import HTTPError\n",
        "from pathlib import Path"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class color:\n",
        "   PURPLE = '\\033[95m'\n",
        "   CYAN = '\\033[96m'\n",
        "   DARKCYAN = '\\033[36m'\n",
        "   BLUE = '\\033[94m'\n",
        "   GREEN = '\\033[92m'\n",
        "   YELLOW = '\\033[93m'\n",
        "   RED = '\\033[91m'\n",
        "   BOLD = '\\033[1m'\n",
        "   UNDERLINE = '\\033[4m'\n",
        "   END = '\\033[0m'\n",
        "# print(color.BOLD + 'Hello, World!' + color.END)"
      ],
      "metadata": {
        "id": "VUgupcK0yLGL"
      },
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections.abc import Mapping\n",
        "\n",
        "def get_authors(dict) -> list:\n",
        "  try:\n",
        "    authors = dict['PubmedArticleSet']['PubmedArticle']['MedlineCitation']['Article']['AuthorList']['Author']\n",
        "    if isinstance(authors, list):\n",
        "      lst = []\n",
        "      for author in authors:\n",
        "        try:\n",
        "          lst += [author['LastName'] + \" \" + author['ForeName']]\n",
        "        except KeyError:\n",
        "          lst += [author['CollectiveName']]\n",
        "      return lst\n",
        "    elif isinstance(authors, Mapping):\n",
        "      try:\n",
        "        return [authors['LastName'] + \" \" + authors['ForeName']]\n",
        "      except KeyError:\n",
        "        return [authors['CollectiveName']]\n",
        "    else:\n",
        "      assert False\n",
        "  except KeyError:\n",
        "    return []\n",
        "\n",
        "  \n",
        "\n",
        "\n",
        "def get_title(dict) -> str:\n",
        "  return dict['PubmedArticleSet']['PubmedArticle']['MedlineCitation']['Article']['ArticleTitle']\n",
        "\n",
        "\n",
        "def get_abstract(dict) -> str:\n",
        "  text = \"\"\n",
        "  try:\n",
        "    abstract =  dict['PubmedArticleSet']['PubmedArticle']['MedlineCitation']['Article']['Abstract']['AbstractText']\n",
        "  except KeyError as e:\n",
        "    return \"\"\n",
        "  if isinstance(abstract, list):\n",
        "    for el in abstract:\n",
        "      text += el[\"@Label\"] + \"\\n\" + el[\"#text\"]\n",
        "      if el != abstract[-1]:\n",
        "         text += \"\\n\"\n",
        "  elif isinstance(abstract, Mapping):\n",
        "    try:\n",
        "      text = abstract[\"#text\"]\n",
        "    except KeyError as e:\n",
        "      try:\n",
        "        text = abstract[\"i\"]\n",
        "      except KeyError as e:\n",
        "        print(e)\n",
        "        assert False\n",
        "  else:\n",
        "    try:\n",
        "      assert isinstance(abstract, str)\n",
        "      text = abstract\n",
        "    except AssertionError:\n",
        "      print(f\"Abstract type: {type(abstract)}\")\n",
        "      assert False\n",
        "  return text\n",
        "\n",
        "\n",
        "def get_keywords(dict) -> list:\n",
        "  try:\n",
        "    return [el['#text'] for el in dict['PubmedArticleSet']['PubmedArticle']['MedlineCitation']['KeywordList']['Keyword']]\n",
        "  except:\n",
        "    return []\n",
        "\n",
        "\n",
        "def get_refs(dict) -> list:\n",
        "  global global_special_ref_counter\n",
        "  cites = []\n",
        "  try:\n",
        "    refs = dict['PubmedArticleSet']['PubmedArticle']['PubmedData']['ReferenceList']['Reference']\n",
        "    if not isinstance(refs, list):\n",
        "      refs = [refs]\n",
        "    for el in refs:\n",
        "      try:\n",
        "        for id in el['ArticleIdList'][\"ArticleId\"]:\n",
        "          try:\n",
        "            if isinstance(id, Mapping) and id['@IdType'] == \"pubmed\":\n",
        "              cites += [id['#text']]\n",
        "            else:\n",
        "              return [] ############################################################\n",
        "          except KeyError as e:\n",
        "            continue\n",
        "      except KeyError as e:\n",
        "        continue\n",
        "  except KeyError as e:\n",
        "    return []\n",
        "  except TypeError:\n",
        "    global_special_ref_counter += 1\n",
        "    return dict['PubmedArticleSet']['PubmedArticle']['PubmedData']['ReferenceList']\n",
        "  return cites"
      ],
      "metadata": {
        "id": "rjy4f5ifv7mX"
      },
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "\n",
        "def save_row(csv_writer, file_name, paper_id, xml_str):\n",
        "    row = raw2row(file_name, paper_id, xml_str)\n",
        "    csv_writer.writerow(row)\n",
        "\n",
        "\n",
        "\n",
        "def save_new_file(old_file_path, save_dir):\n",
        "    global global_failure_counter\n",
        "    df = pd.read_csv(old_file_path, header=None)\n",
        "    length = len(df)\n",
        "    stem = Path(old_file_path).stem\n",
        "    date = datetime.strptime(stem, '%Y_%m_%d')\n",
        "    new_file_path = os.path.join(save_dir, stem + \"_text.csv\")\n",
        "    with open(new_file_path,'a+') as out:\n",
        "        csv_writer=csv.writer(out, dialect='unix')\n",
        "        for idx in range(length):\n",
        "            paper_id = df[0][idx]\n",
        "            xml_str = df[1][idx]\n",
        "            # print(paper_id)\n",
        "            # print(xml_str)\n",
        "            try:\n",
        "              title, authors, keywords, abstract, references = process_xml(file_name, paper_id, xml_str)\n",
        "            except KeyError as e:\n",
        "              global_failure_counter += 1\n",
        "              print(color.BOLD + color.RED + f'>>>>>>>> Failed to process {paper_id} [{stem}] <<<<<<<<<' + color.END)\n",
        "            except:\n",
        "              print(f\"Finished to process {paper_id} [{stem}]\")\n",
        "              assert False\n",
        "            csv_writer.writerow([paper_id, date, title, authors, keywords, abstract, references])\n",
        "    print(f\"Processed {length} papers published on {stem}.\")\n",
        "    pass"
      ],
      "metadata": {
        "id": "dwbC99AQ0r1B"
      },
      "execution_count": 154,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ! pip install xmltodict\n",
        "import xmltodict\n",
        "\n",
        "def process_xml(file_name, paper_id, xml_str):\n",
        "    dict = xmltodict.parse(xml_str)\n",
        "    authors = get_authors(dict)\n",
        "    title = get_title(dict)\n",
        "    abstract = get_abstract(dict)\n",
        "    keywords = get_keywords(dict)\n",
        "    references = get_refs(dict)\n",
        "    # print(f\"Failed to process {paper_id}\")\n",
        "    result_list = [title, authors, keywords, abstract, references]\n",
        "    for i, _ in enumerate(result_list):\n",
        "      if result_list[i] == []:\n",
        "        result_list[i] = \"\"\n",
        "    return result_list"
      ],
      "metadata": {
        "id": "EDDCkfmb5MDW"
      },
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "year = \"2022\"\n",
        "# month = 12\n",
        "global_special_ref_counter = 0\n",
        "global_failure_counter = 0\n",
        "for m in range(4, 13):\n",
        "\n",
        "        month = f\"{m:02}\"\n",
        "        xml_dir = os.path.join(proj_dir, \"xmls\", year, month)\n",
        "        save_dir = Path(os.path.join(proj_dir, \"text_csv\", year, month))\n",
        "        save_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "        for file_name in os.listdir(xml_dir):\n",
        "            save_new_file(os.path.join(xml_dir, file_name), save_dir)\n",
        "print(f\"global_special_ref_counter: {global_special_ref_counter}\")\n",
        "print(f\"global_failure_counter: {global_failure_counter}\")"
      ],
      "metadata": {
        "id": "kBxmRgZSNo3a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inspecting the errors"
      ],
      "metadata": {
        "id": "1oPLWU6mhW4F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# df = pd.read_csv(\"/gdrive/MyDrive/dsr/pubmed_data/xmls/2022/04/2022_04_01.csv\", header=None)\n",
        "# problem_id = 35247637\n",
        "\n",
        "# xml_str = df[df[0] == problem_id].iloc[0, 1]\n",
        "# dict = xmltodict.parse(xml_str)\n",
        "# # dict['PubmedArticleSet']['PubmedArticle']['MedlineCitation']['Article']['Abstract']['AbstractText']\n",
        "# dict"
      ],
      "metadata": {
        "id": "m0McdWRLpIjm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71bd8643-d945-45cd-c90e-6645775f1d9c"
      },
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'PubmedArticleSet': {'pubmed': None}}"
            ]
          },
          "metadata": {},
          "execution_count": 143
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "rl",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}