{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from Bio import Entrez\n",
    "Entrez.email = \"example@example.com\"\n",
    "from urllib.error import HTTPError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pmids_from_one_day(topic, date):\n",
    "    handle = Entrez.esearch(db=\"pubmed\", \n",
    "                            term= topic + \"[MeSH Terms]\", \n",
    "                            retmax=1000,\n",
    "                            datetype=\"pdat\", \n",
    "                            mindate=date, \n",
    "                            maxdate=date, )\n",
    "    record = Entrez.read(handle)\n",
    "    ids = record[\"IdList\"]\n",
    "    return ids\n",
    "\n",
    "\n",
    "class color:\n",
    "   PURPLE = '\\033[95m'\n",
    "   CYAN = '\\033[96m'\n",
    "   DARKCYAN = '\\033[36m'\n",
    "   BLUE = '\\033[94m'\n",
    "   GREEN = '\\033[92m'\n",
    "   YELLOW = '\\033[93m'\n",
    "   RED = '\\033[91m'\n",
    "   BOLD = '\\033[1m'\n",
    "   UNDERLINE = '\\033[4m'\n",
    "   END = '\\033[0m'\n",
    "# print(color.BOLD + 'Hello, World!' + color.END)\n",
    "\n",
    "def print_err(text):\n",
    "    err_text = color.BOLD + color.RED + text + color.END\n",
    "    print(err_text)\n",
    "    return err_text\n",
    "\n",
    "def get_pmids_from_period(topic, span):\n",
    "    handle = Entrez.esearch(db=\"pubmed\", \n",
    "                            term= topic + \"[MeSH Terms]\", \n",
    "                            retmax=1000,\n",
    "                            datetype=\"pdat\", \n",
    "                            mindate=span[0], \n",
    "                            maxdate=span[1], )\n",
    "    record = Entrez.read(handle)\n",
    "    ids = record[\"IdList\"]\n",
    "    return ids\n",
    "\n",
    "\n",
    "import time\n",
    "def get_xml(id):\n",
    "    attempt = 1\n",
    "    while attempt <= 3:\n",
    "        try:\n",
    "            handle = Entrez.efetch(db=\"pubmed\", \n",
    "                            id=id, \n",
    "                            retmode=\"xml\", \n",
    "                            rettype=\"abstract\")\n",
    "            xml = handle.read()\n",
    "            return xml\n",
    "        except HTTPError as err:\n",
    "            if 500 <= err.code <= 599:\n",
    "                print_err(f\">>>>> Attempt {attempt}: Received error from server {err}\")\n",
    "                attempt += 1\n",
    "                time.sleep(15)\n",
    "            else:\n",
    "                print_err(f\">>>>> Failed to download {id}. Error: {err}\")\n",
    "                return \"\"\n",
    "    \n",
    "    # pp = pprint.PrettyPrinter(indent=4)\n",
    "    # pp.pprint(json.dumps(xmltodict.parse(xml)))\n",
    "\n",
    "\n",
    "\n",
    "def get_xmls_ids(ids):\n",
    "    pairs = []\n",
    "    for id in tqdm(ids):\n",
    "        xml = get_xml(id)\n",
    "        pairs += [(id, xml)]\n",
    "    return pairs\n",
    "\n",
    "\n",
    "import csv\n",
    "def save_span(span, list_of_pairs):\n",
    "    file_name = span[0].replace(\"/\", \"_\") + \"__\" + span[1].replace(\"/\", \"_\") + \".csv\"\n",
    "    with open(file_name,'w') as out:\n",
    "        csv_out=csv.writer(out, dialect='unix')\n",
    "        # csv_out.writerow(['name','num'])\n",
    "        # for row in list_of_pairs:\n",
    "        #     csv_out.writerow(row)\n",
    "        csv_out.writerows(list_of_pairs)\n",
    "    return file_name\n",
    "\n",
    "\n",
    "def save_date(date, list_of_pairs):\n",
    "    file_name = date.replace(\"/\", \"_\") + \".csv\"\n",
    "    with open(file_name,'w') as out:\n",
    "        csv_out=csv.writer(out, dialect='unix')\n",
    "        # csv_out.writerow(['name','num'])\n",
    "        # for row in list_of_pairs:\n",
    "        #     csv_out.writerow(row)\n",
    "        csv_out.writerows(list_of_pairs)\n",
    "        print(f\"Saved {len(list_of_pairs)} papers published on {date}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting with 2022/03/01\n",
      "Number of papers published on  2022/03/01': 719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 24/719 [00:24<20:31,  1.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[91m>>>>> Failed to download 35428464. Error: HTTP Error 400: Bad Request\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 59/719 [00:59<11:21,  1.03s/it]"
     ]
    }
   ],
   "source": [
    "month = '03'\n",
    "\n",
    "for day in range(1, 32):\n",
    "    date = \"2022/\" + month + \"/\" + f'{day:02}'\n",
    "    print(f\"Starting with {date}\")\n",
    "    ids = get_pmids_from_one_day(\"breast cancer\", date)\n",
    "    if len(ids) == 0:\n",
    "        break\n",
    "    print(f\"Number of papers published on  {date}': {len(ids)}\")\n",
    "    pairs = get_xmls_ids(ids)\n",
    "    file_name = save_date(date, pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_name = '2022_01_02__2022_01_10.csv'\n",
    "# df = pd.read_csv(file_name, header=None)\n",
    "# df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
